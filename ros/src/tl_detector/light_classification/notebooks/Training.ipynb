{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from random import randint\n",
    "import math\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Input, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Lambda, concatenate, ELU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = [\"red\", \"green\", \"yellow\"]\n",
    "input_img_x = 32\n",
    "input_img_y = 32\n",
    "\n",
    "full_set = []\n",
    "for im_type in image_types:\n",
    "    for ex in glob.glob(os.path.join(\"../dataset/\", im_type, \"*\")):\n",
    "        im = cv2.imread(ex)\n",
    "        if not im is None:\n",
    "            # Resize image\n",
    "            im = cv2.resize(im, (input_img_x, input_img_y))\n",
    "\n",
    "            # Convert to RGB\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
    "            \n",
    "            # Create an array representing our classes and set it\n",
    "            one_hot_array = [0] * len(image_types)\n",
    "            one_hot_array[image_types.index(im_type)] = 1\n",
    "            assert(im.shape == (input_img_x, input_img_y, 3))\n",
    "\n",
    "            # Add it to our set\n",
    "            full_set.append((im, one_hot_array, ex))\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(full_set)\n",
    "print(len(full_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split and batch size\n",
    "train_test_split_ratio = 0.9\n",
    "batch_size = 32\n",
    "\n",
    "# We split our data into a training and test set here\n",
    "split_index = int(math.floor(len(full_set) * train_test_split_ratio))\n",
    "print(split_index)\n",
    "train_set = full_set[:split_index]\n",
    "print(len(train_set))\n",
    "test_set = full_set[split_index:]\n",
    "\n",
    "# # We ensure that our training and test sets are a multiple of batch size\n",
    "# train_set_offset = len(train_set) % batch_size\n",
    "# test_set_offset = len(test_set) % batch_size\n",
    "# train_set = train_set[: len(train_set) - train_set_offset]\n",
    "# test_set = test_set[: len(test_set) - test_set_offset]\n",
    "\n",
    "# Split\n",
    "train_x, train_y, train_z = zip(*train_set)\n",
    "test_x, test_y, test_z = zip(*test_set)\n",
    "\n",
    "# Convert to numpy array\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "print(\"Training samples: {}\".format(len(train_y)))\n",
    "print(\"Test samples: {}\".format(len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    majority = max(counts)\n",
    "    return  {cls: float(majority/count) for cls, count in zip(unique, counts)}\n",
    "\n",
    "train_y_dec = np.argmax(train_y, axis=1)\n",
    "class_weights = get_class_weights(train_y_dec)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_module(x, fire_id, squeeze=16, expand=64): \n",
    "    # Squeeze part with 1x1 conv\n",
    "    x = Conv2D(squeeze, (1, 1), padding='valid', name='fire' + str(fire_id) + '/' + \"squeeze1x1\")(x)\n",
    "    x = Activation('elu', name='fire' + str(fire_id) + '/elu_squeeze1x1')(x)\n",
    "    # Expand part with 1x1 conv\n",
    "    left = Conv2D(expand, (1, 1), padding='valid', name='fire' + str(fire_id) + '/' + \"expand1x1\")(x)\n",
    "    left = Activation('elu', name='fire' + str(fire_id) + '/elu_expand1x1')(left)\n",
    "    # Expand part with 3x3 conv\n",
    "    right = Conv2D(expand, (3, 3), padding='same', name='fire' + str(fire_id) + '/' + \"expand3x3\")(x)\n",
    "    right = Activation('elu', name='fire' + str(fire_id) + '/elu_expand3x3')(right)\n",
    "    # Fuse left and right expansion together\n",
    "    x = concatenate([left, right], axis=3, name='fire' + str(fire_id) + '/' + 'concat')\n",
    "    return x\n",
    "\n",
    "def squeeze_model():\n",
    "    # Shape of our input image is 32x32x3\n",
    "    input_img = Input(shape=(32, 32, 3))\n",
    "    \n",
    "    # This is our normalization from 0 to 1\n",
    "    x = Lambda(lambda x: x/255.0, input_shape=(32, 32, 3))(input_img)\n",
    "    \n",
    "    # Use two fire modules with 16 filter squeeze and 64 filter expand\n",
    "    x = fire_module(x, fire_id=1, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Use two fire modules with 32 filter squeeze and 128 filter expand\n",
    "    x = fire_module(x, fire_id=3, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Use two fire modules with 48 filter squeeze and 192 filter expand\n",
    "    x = fire_module(x, fire_id=5, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # Dropout with drop rate 20%\n",
    "    x = Dropout(0.2)(x)  \n",
    "    \n",
    "    # Last conv layer\n",
    "    x = Conv2D(100, (1, 1), padding='valid')(x)\n",
    "    x = Activation('elu')(x)\n",
    "    \n",
    "    # Do a global average pooling\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # This is our output layer for the three classes with softmax\n",
    "    out = Dense(3, name='loss', activation=\"softmax\")(x)\n",
    "    \n",
    "    # Build our model\n",
    "    model = Model(inputs=input_img, outputs=[out])     \n",
    "    return model\n",
    "\n",
    "model = squeeze_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of epochs for training\n",
    "epochs = 2\n",
    "\n",
    "# Let's train the model using Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for checkpoints, visualisation and early stop\n",
    "check_point = ModelCheckpoint('../checkpoints/model-e{epoch:03d}.h5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='min')\n",
    "        \n",
    "history = model.fit(x=train_x,y=train_y,verbose=2,batch_size=batch_size,epochs=epochs,\n",
    "                    validation_data = (test_x, test_y), callbacks=[early_stop, check_point])\n",
    "\n",
    "# Save the model to file\n",
    "model.save('../models/model.h5')\n",
    "\n",
    "# Print message\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)\n",
    "model = load_model(\"../models/model.h5\")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    sfmax = list(model.predict(image, verbose=0)[0])\n",
    "    sf_ind = sfmax.index(max(sfmax))\n",
    "    predicted_label = image_types[sf_ind]\n",
    "    return predicted_label\n",
    "\n",
    "image = test_x[randint(0, len(test_x))]\n",
    "plt.imshow(image)\n",
    "img = np.reshape(image, (1, 32, 32, 3))\n",
    "print(predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [None]\n",
    "pred_node_names = [None]\n",
    "pred_node_names[0] = 'output_'+str(0)\n",
    "pred[0] = tf.identity(model.output[0], name=pred_node_names[0])\n",
    "sess = K.get_session()\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "graph_io.write_graph(constant_graph, 'model', 'model_classification.pb', as_text=False)\n",
    "print('Keras model converted to TensorFlow model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a graph from a protobuf file\n",
    "def load_graph(graph_file):\n",
    "    with tf.Session(graph=tf.Graph(), config=config) as sess:\n",
    "        gd = tf.GraphDef()\n",
    "        with tf.gfile.Open(graph_file, 'rb') as f:\n",
    "            data = f.read()\n",
    "            gd.ParseFromString(data)\n",
    "        tf.import_graph_def(gd, name='')\n",
    "        return sess.graph\n",
    "\n",
    "# Enable optimizations\n",
    "config = tf.ConfigProto()\n",
    "jit_level = tf.OptimizerOptions.ON_1\n",
    "config.graph_options.optimizer_options.global_jit_level = jit_level    \n",
    "\n",
    "# Load graph from protobuf file\n",
    "graph = load_graph(os.path.join('model', 'model_classification.pb'))\n",
    "\n",
    "# Get input and output tensors\n",
    "in_graph = graph.get_tensor_by_name('input_1_1:0')\n",
    "out_graph = graph.get_tensor_by_name('output_0:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image from the test set\n",
    "image = test_x[randint(0, len(test_x))]\n",
    "plt.imshow(image)\n",
    "\n",
    "# Do the prediction here\n",
    "with tf.Session(graph=graph, config=config) as sess:   \n",
    "    sfmax = list(sess.run(tf.nn.softmax(out_graph.eval(feed_dict={in_graph: [image]}))))\n",
    "    sf_ind = sfmax.index(max(sfmax))\n",
    "    predicted_label = image_types[sf_ind]\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
